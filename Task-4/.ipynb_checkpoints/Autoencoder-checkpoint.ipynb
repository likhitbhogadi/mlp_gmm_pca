{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d82c7-c44e-4b5e-861a-d8b91b4f793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de294f1-7e57-417f-b90f-8fef9264b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28*28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f39223-8a93-4aa5-81aa-fd98a7997749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])\n",
    "dataset = MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "test_dataset = MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "# Define normal digit based on roll number's last digit\n",
    "normal_digit = 7 \n",
    "normal_indices = [i for i, (img, label) in enumerate(dataset) if label == normal_digit]\n",
    "# print(len(normal_indices))\n",
    "normal_dataset = Subset(dataset, normal_indices)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(normal_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd818df-6ee8-4165-8534-475dbd191b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(1,epochs+1):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        images, _ = batch\n",
    "        optimizer.zero_grad()\n",
    "        recon = model(images)\n",
    "        loss = criterion(recon, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if epoch%10 == 0:\n",
    "        print(f\"Epoch [{epoch}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8b1ae-4760-413d-84b2-2cecf5ee1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute reconstruction error for test data\n",
    "reconstruction_errors = []\n",
    "labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, lbls in test_loader:\n",
    "        outputs = model(images)\n",
    "        loss = ((outputs - images) ** 2).mean(dim=1)\n",
    "        reconstruction_errors.extend(loss.numpy())\n",
    "        labels.extend(lbls.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc330bb-b212-44ed-8318-ce5355051646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "reconstruction_errors = np.array(reconstruction_errors)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(reconstruction_errors[labels == normal_digit], bins=50, alpha=0.5, label=\"Normal\")\n",
    "plt.hist(reconstruction_errors[labels != normal_digit], bins=50, alpha=0.5, label=\"Anomalous\")\n",
    "plt.xlabel(\"Reconstruction Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.title(\"Histogram of Reconstruction Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30503d0d-794b-43bc-81a0-a459aa58e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold for anomaly detection (95th percentile of normal data errors)\n",
    "threshold = np.percentile(reconstruction_errors[labels == normal_digit], 95)\n",
    "print(f\"Threshold:{threshold}\")\n",
    "\n",
    "# Predictions: 1 = Anomalous, 0 = Normal\n",
    "predictions = (reconstruction_errors > threshold).astype(int)\n",
    "true_labels = (labels != normal_digit).astype(int)  # 1 for anomaly, 0 for normal\n",
    "\n",
    "# Compute Metrics\n",
    "precision = precision_score(true_labels, predictions)\n",
    "recall = recall_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982c090-b0e7-4f19-8c86-7282ca993114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, bottleneck_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, bottleneck_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(bottleneck_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28 * 28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390f473-ec26-42ed-80d7-b9bd2525f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_sizes = [16, 32, 64]\n",
    "auc_scores = {}\n",
    "\n",
    "for bottleneck in bottleneck_sizes:\n",
    "    print(f\"Training Autoencoder with Bottleneck Size: {bottleneck}\")\n",
    "\n",
    "    # Initialize the model\n",
    "    model = Autoencoder(bottleneck)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            images, _ = batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Compute reconstruction errors\n",
    "    reconstruction_errors = []\n",
    "    labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, lbls in test_loader:\n",
    "            outputs = model(images)\n",
    "            loss = ((outputs - images) ** 2).mean(dim=1)\n",
    "            reconstruction_errors.extend(loss.numpy())\n",
    "            labels.extend(lbls.numpy())\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    reconstruction_errors = np.array(reconstruction_errors)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # True labels: 1 for anomaly, 0 for normal\n",
    "    true_labels = (labels != normal_digit).astype(int)\n",
    "\n",
    "    # Compute ROC curve and AUC score\n",
    "    fpr, tpr, _ = roc_curve(true_labels, reconstruction_errors)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_scores[bottleneck] = roc_auc\n",
    "\n",
    "    # Plot ROC Curve\n",
    "    plt.plot(fpr, tpr, label=f\"Bottleneck {bottleneck} (AUC = {roc_auc:.4f})\")\n",
    "\n",
    "# Final ROC Curve Plot\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")  # Diagonal Line\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for Different Bottleneck Sizes\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print AUC Scores\n",
    "for bottleneck, score in auc_scores.items():\n",
    "    print(f\"Bottleneck Size {bottleneck}: AUC = {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca2b47-68dc-4dbf-a4db-909bdc1393d2",
   "metadata": {},
   "source": [
    "# **Observations on Autoencoder Performance with Different Bottleneck Sizes**\n",
    "\n",
    "## **Introduction**\n",
    "Autoencoders are trained to compress and reconstruct input data. The bottleneck size (latent dimension) affects how well the model captures key features.  \n",
    "\n",
    "In this experiment, we tested three different **bottleneck sizes (16, 32, 64)** and evaluated their performance using the **AUC-ROC score**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Analysis of the ROC Curve**\n",
    "1. **Bottleneck 32 performs the best**  \n",
    "   - It achieves the highest **AUC score of 0.9705**.  \n",
    "   - This suggests that it captures important features **without excessive compression or unnecessary complexity**.  \n",
    "\n",
    "2. **Bottleneck 16 has a slightly lower AUC (0.9679)**  \n",
    "   - The model struggles to retain enough information due to the extreme compression.  \n",
    "   - Some key features might be lost, leading to **slightly worse classification performance**.  \n",
    "\n",
    "3. **Bottleneck 64 has the lowest AUC (0.9655)**  \n",
    "   - Despite having more latent features, performance does not improve.  \n",
    "   - This may indicate **overfitting**, where the model memorizes details rather than generalizing well.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Key Takeaways**\n",
    "**Balanced Compression is Crucial**  \n",
    "- A bottleneck **too small** (16) loses information.  \n",
    "- A bottleneck **too large** (64) may overfit.  \n",
    "- **Bottleneck 32 provides the best balance**.  \n",
    "\n",
    " **AUC-ROC Score is a Useful Metric**  \n",
    "- AUC values close to **1.0 indicate better separability** between normal and anomaly classes.  \n",
    "- All three models perform well, but **Bottleneck 32 achieves the best trade-off**.  \n",
    "\n",
    " **Hyperparameter Tuning Matters**  \n",
    "- Choosing an optimal bottleneck **significantly impacts performance**.  \n",
    "- Further tuning (e.g., regularization, different architectures) could **further refine results**.  \n",
    "\n",
    " **Next Steps**: Try **different architectures (e.g., deeper layers, convolutional autoencoders)** to see if we can further improve performance!  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7bfc05-91a9-493a-8981-3e472b5f6618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting a batch of original and reconstructed images\n",
    "# Get some test images\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    images, _ = next(iter(test_loader))  # Get a batch of test images\n",
    "    outputs = model(images)  # Reconstruct images\n",
    "\n",
    "# Convert images back to 28x28 format\n",
    "images = images.view(-1, 28, 28)\n",
    "outputs = outputs.view(-1, 28, 28)\n",
    "\n",
    "# Plot Original and Reconstructed Images\n",
    "num_images = 10  # Number of images to display\n",
    "fig, axes = plt.subplots(2, num_images, figsize=(15, 4))\n",
    "\n",
    "for i in range(num_images):\n",
    "    # Original images\n",
    "    axes[0, i].imshow(images[i].cpu().numpy(), cmap=\"gray\")\n",
    "    axes[0, i].axis(\"off\")\n",
    "    \n",
    "    # Reconstructed images\n",
    "    axes[1, i].imshow(outputs[i].cpu().numpy(), cmap=\"gray\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "axes[0, 0].set_title(\"Original Images\")\n",
    "axes[1, 0].set_title(\"Reconstructed Images\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890598e7-6985-414d-9f48-c005a5e2a7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
